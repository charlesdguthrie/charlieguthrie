---
title: "Engagement vs. Performance on the MedU Platform"
subtitle: "Progress Report 2016-03-21"
author: "Charlie Guthrie"
date: "March 21, 2016"
output: html_document
---


##Project Overview
I'm building a model to predict a student's performance in an online course from his/her level of engagement in the class. The ultimate goal is to determine which engagement activities contribute most to student performance and understanding. I'm using a data set from NYU Langone from MedU, an online learning platform for medical courses.



##About the Data
Student performance is measured by score on multiple-choice questions throughout the 23-card unit.  
See a screenshot of a sample card below.

![Screenshot of sample learning card](../figures/card_screenshot.png)

###Key Variables
Variables that may have an impact on student performance:

  * Clicking hyperlinks
  * Enlarging images
  * Checking answers
  * Time spent on cards
  
###Sample Data
```{r cache=FALSE}
library(knitr)
setwd("~/git/edsp/notebooks")
source('../scripts/explore_data.R')
df = load_data()

source('../scripts/processing.R')
outdf = restructure(df)
outdf = rename_cols(outdf,new_names)
kable(head(outdf))
outdf = transform_vars(outdf)
data = train_test_split(outdf)
train=data[[1]]
test=data[[2]]
hist(outdf$success)
hist(outdf$handling_time)
hist(outdf$hyperlink_clicks)
hist(outdf$magnify_clicks)
hist(outdf$expert_clicks)

```

##First Models
```{r results="hide"}
source('../scripts/models.R')
```

###Logistic
There appears to be a strong relationship between performance and clicks on the magnify button and expert buttons.  But the relationship is less clear with handling time and hyperlink clicks. 
```{r}
mylogit <- glm(label ~ hyperlink_clicks + magnify_clicks + expert_clicks + handling_time, data = train, family = "binomial")
summary(mylogit)
```

However, the model still needs a lot of work. It does not appear very accurate.

Train Accuracy:
```{r echo=FALSE}
train_tab = confusion_matrix(mylogit,train)
print(train_tab)
accuracy = get_accuracy(train_tab)
print(c("accuracy:",accuracy))
```

Test Accuracy:
```{r echo=FALSE}
tab = confusion_matrix(mylogit,test)
print(tab)
accuracy = get_accuracy(tab)
print(c("accuracy:",accuracy))
```

###Decision Tree
Next I tried a decision tree, borrowing code from the classification tutorial:
```{r}
mydat_tree <- ctree(label ~ hyperlink_clicks + magnify_clicks + expert_clicks + handling_time, data = train)
plot(mydat_tree)
```

Train Accuracy:
```{r echo=FALSE}
tab = confusion_matrix(mydat_tree,train)
print(tab)
accuracy = get_accuracy(tab)
print(c("accuracy:",accuracy))
```

Test Accuracy:
```{r echo=FALSE}
tab = confusion_matrix(mydat_tree,test)
print(tab)
accuracy = get_accuracy(tab)
print(c("accuracy:",accuracy))
```


##Log-transform and binary variables
Here I convert hyperlink, magnify and expert link clicks to binary (0 vs 1+) and handling time to logistic

```{r}
mylogit2 <- glm(label ~ hyperlink_clicked + magnify_clicked + expert_clicked + log_handling_time, data = train, family = "binomial")
summary(mylogit2)
```

However, the model still needs a lot of work. It does not appear very accurate.

Train Accuracy:
```{r echo=FALSE}
train_tab = confusion_matrix(mylogit2,train)
print(train_tab)
accuracy = get_accuracy(train_tab)
print(c("accuracy:",accuracy))
```

Test Accuracy:
```{r echo=FALSE}
tab = confusion_matrix(mylogit2,test)
print(tab)
accuracy = get_accuracy(tab)
print(c("accuracy:",accuracy))
```

###Decision Tree
Next I tried a decision tree, borrowing code from the classification tutorial:
```{r}
mydat_tree2 <- ctree(label ~ hyperlink_clicked + magnify_clicked + expert_clicked + log_handling_time, data = train)
plot(mydat_tree2)
```

Train Accuracy:
```{r echo=FALSE}
tab = confusion_matrix(mydat_tree2,train)
print(tab)
accuracy = get_accuracy(tab)
print(c("accuracy:",accuracy))
```

Test Accuracy:
```{r echo=FALSE}
tab = confusion_matrix(mydat_tree2,test)
print(tab)
accuracy = get_accuracy(tab)
print(c("accuracy:",accuracy))
```

##Next Steps
There is still a lot of work to do. I will tweak the logistic classifier, trying out different variables and variations on the existing variables.  

The tree classifier shows more promise. 

I also want to visualize the results better

##Individual Cards
Here I'll attempt to separate out model performance for each individual assessment card, rather than lumping them all together. This will solve two problems: one, that success is measured differently for different assessment cards.  And two, it can tell me the relative impact that different activity cards have on their respective assessments. For example, maybe activity cards 1-4 impact assessment card 5 more than activities 6-9 do on assessment 10.  



