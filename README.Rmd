---
title: "Engagement vs. Performance on the MedU Platform"
author: "Charlie Guthrie"
date: "April 18, 2016"
output: md_document
variant: markdown_github
subtitle: Progress Report 2016-03-21
---


##Project Overview
I'm building a model to predict a student's performance in an online course from his/her level of engagement in the class. The ultimate goal is to determine which engagement activities contribute most to student performance and understanding. I'm using a data set from NYU Langone from MedU, an online learning platform for medical courses.



##About the Data
Student performance is measured by score on multiple-choice questions throughout the 23-card unit.  
See a screenshot of a sample card below.

![Screenshot of sample learning card](figures/card_screenshot.png)

###Key Variables
Variables that may have an impact on student performance:

  * Clicking hyperlinks
  * Enlarging images
  * Checking answers
  * Time spent on cards
  
###Sample Data
```{r}
library(knitr)
source('scripts/explore_data.R')
df = load_data('data/fullData.csv','data/dataDefs.csv')

source('scripts/processing.R')
data = process_data(df)
train=data[[1]]
test=data[[2]]

hist(train$success)
hist(train$handling_time)
hist(train$hyperlink_clicks)
hist(train$magnify_clicks)
hist(train$expert_clicks)
```

##First Models
```{r results="hide"}
source('scripts/models.R')
```

###Logistic
There appears to be a strong relationship between performance and clicks on the magnify button and expert buttons.  But the relationship is less clear with handling time and hyperlink clicks. 
```{r}
mylogit <- glm(label ~ hyperlink_clicks + magnify_clicks + expert_clicks + handling_time, data = train, family = "binomial")
summary(mylogit)
```

However, the model still needs a lot of work. It does not appear very accurate.

Train Accuracy:
```{r echo=FALSE}
train_tab = confusion_matrix(mylogit,train)
print(train_tab)
accuracy = get_accuracy(train_tab)
print(c("accuracy:",accuracy))
```

Test Accuracy:
```{r echo=FALSE}
tab = confusion_matrix(mylogit,test)
print(tab)
accuracy = get_accuracy(tab)
print(c("accuracy:",accuracy))
```

###Decision Tree
Next I tried a decision tree, borrowing code from the classification tutorial:
```{r}
mydat_tree <- ctree(label ~ hyperlink_clicks + magnify_clicks + expert_clicks + handling_time, data = train)
plot(mydat_tree)
```

Train Accuracy:
```{r echo=FALSE}
tab = confusion_matrix(mydat_tree,train)
print(tab)
accuracy = get_accuracy(tab)
print(c("accuracy:",accuracy))
```

Test Accuracy:
```{r echo=FALSE}
tab = confusion_matrix(mydat_tree,test)
print(tab)
accuracy = get_accuracy(tab)
print(c("accuracy:",accuracy))
```


##Log-transform and binary variables
Here I convert hyperlink, magnify and expert link clicks to binary (0 vs 1+) and handling time to logistic

```{r}
mylogit2 <- glm(label ~ hyperlink_clicked + magnify_clicked + expert_clicked + log_handling_time, data = train, family = "binomial")
summary(mylogit2)
```

However, the model still needs a lot of work. It does not appear very accurate.

Train Accuracy:
```{r echo=FALSE}
train_tab = confusion_matrix(mylogit2,train)
print(train_tab)
accuracy = get_accuracy(train_tab)
print(c("accuracy:",accuracy))
```

Test Accuracy:
```{r echo=FALSE}
tab = confusion_matrix(mylogit2,test)
print(tab)
accuracy = get_accuracy(tab)
print(c("accuracy:",accuracy))
```

###Decision Tree
Decision tree with the binary and logistic variables.
```{r}
mydat_tree2 <- ctree(label ~ hyperlink_clicked + magnify_clicked + expert_clicked + log_handling_time, data = train)
plot(mydat_tree2)
```

Train Accuracy:
```{r echo=FALSE}
tab = confusion_matrix(mydat_tree2,train)
print(tab)
accuracy = get_accuracy(tab)
print(c("accuracy:",accuracy))
```

Test Accuracy:
```{r echo=FALSE}
tab = confusion_matrix(mydat_tree2,test)
print(tab)
accuracy = get_accuracy(tab)
print(c("accuracy:",accuracy))
```


##Bucketing handling time
Bucket handling time into segments: for each unit there is an indicator for if the student spent less than 20 seconds on it, as well an indicator for spending more than 100 seconds.
```{r}
logit <- glm(label ~ hyperlink_clicked + magnify_clicked + expert_clicked + time_lt_20 + time_gt_100, data = train, family = "binomial")
print(summary(logit))
tab = confusion_matrix(logit,train)
print(tab)
accuracy = get_accuracy(tab)
print(c("logit accuracy:",accuracy))
```
Spending a very short time (<20 seconds) on the learning activities does indeed make a student less likely to succeed on the assessment. On the other hand spending more than 100 seconds makes a student more likely to succeed

##Individual Assessment Cards
Here I'll attempt to separate out model performance for each individual assessment card, rather than lumping them all together. This will solve two problems: one, that success is measured differently for different assessment cards.  And two, it can tell me the relative impact that different activity cards have on their respective assessments. For example, maybe activity cards 1-4 impact assessment card 5 more than activities 6-9 do on assessment 10.  

```{r}
for (a in assessment_cards) {
  cat("\n***************************************************\n----------\n|CARD",a,"|\n----------")
  subtrain = get_single_card(train,a)
  logit <- glm(label ~ hyperlink_clicked + magnify_clicked + expert_clicked + time_lt_20 + time_gt_100, data = subtrain, family = "binomial")
  display_results(logit,subtrain,subtrain$label)
  tree <- ctree(label ~ hyperlink_clicked + magnify_clicked + expert_clicked + log_handling_time, data = subtrain)
  plot(tree)
  tab = confusion_matrix(tree,subtrain)
  print(tab)
  accuracy = get_accuracy(tab)
  print(c("tree accuracy:",accuracy))
}
```

##Individual Assessment Cards and Engagement Cards
Here I split further to try and measure the impact of each engagement card's components on student performance.  For example, rather than combining cards 1-4 and measuring the aggregate impact on performance, I consider engagement activities from card 1 separately from engagement activities on card 2, etc.

```{r}
data_w = widen(df)
train_w = data_w[[1]]
test_w = data_w[[2]]
```

Modeling engagement activities associated with the assessment on card 5:
```{r}
logit <- glm(label_5 ~ 
               hyperlink_clicked_1 + hyperlink_clicked_2 + hyperlink_clicked_4 + hyperlink_clicked_5 
             + magnify_clicked_4 + magnify_clicked_5 
             + time_lt_20_1 + time_lt_20_2 + time_lt_20_3 + time_lt_20_4 + time_lt_20_5
             + time_gt_100_1 + time_gt_100_2 + time_gt_100_3 + time_gt_100_4 + time_gt_100_5,
             data=train_w, family="binomial")
display_results(logit,train_w,train_w$label_5,threshold=0.3)
display_results(logit,test_w,test_w$label_5)
```

Refining the model:
```{r}
logit <- glm(label_5 ~ 
             magnify_clicked_5 
             + time_lt_20_3 + time_lt_20_4 + time_lt_20_5,
             data=train_w, family="binomial")
display_results(logit,train_w,train_w$label_5,0.1)
```

Modeling engagement activities associated with the assessment on card 9:
```{r}
logit <- glm(label_9 ~ 
               hyperlink_clicked_1 + hyperlink_clicked_2 + hyperlink_clicked_4 + hyperlink_clicked_5 + hyperlink_clicked_6 + hyperlink_clicked_8 + hyperlink_clicked_9
             + magnify_clicked_4 + magnify_clicked_5 + magnify_clicked_7 + magnify_clicked_9 
             + time_lt_20_1 + time_lt_20_2 + time_lt_20_3 + time_lt_20_4 + time_lt_20_5 + time_lt_20_6 + time_lt_20_7 + time_lt_20_8 + time_lt_20_9
             + time_gt_100_1 + time_gt_100_2 + time_gt_100_3 + time_gt_100_4 + time_gt_100_5 + time_gt_100_6 + time_gt_100_7 + time_gt_100_8 + time_gt_100_9,
             data=train_w, family="binomial")
display_results(logit,train_w,train_w$label_5,threshold=0.3)
display_results(logit,test_w,test_w$label_5)
```

Refining model 9:
```{r}
logit <- glm(label_9 ~ 
               hyperlink_clicked_6 + hyperlink_clicked_8 + hyperlink_clicked_9
             + magnify_clicked_7 + magnify_clicked_9 
             + time_lt_20_6 + time_lt_20_7 + time_lt_20_8 + time_lt_20_9
             + time_gt_100_6 + time_gt_100_7 + time_gt_100_8 + time_gt_100_9,
             data=train_w, family="binomial")
display_results(logit,train_w,train_w$label_5,threshold=0.3)
display_results(logit,test_w,test_w$label_5)
```

Modeling engagement activities associated with the assessment on card 12:
```{r}
logit <- glm(label_12 ~ 
               hyperlink_clicked_8 + hyperlink_clicked_9 + hyperlink_clicked_10 + hyperlink_clicked_11
             + magnify_clicked_9 + magnify_clicked_11
             + expert_clicked_5 + expert_clicked_9
             + time_lt_20_8 + time_lt_20_9 + time_lt_20_10 + time_lt_20_11
             + time_gt_100_8 + time_gt_100_9 + time_gt_100_10 + time_gt_100_11,
             data=train_w, family="binomial")
display_results(logit,train_w,train_w$label_5,threshold=0.3)
display_results(logit,test_w,test_w$label_5)
```

Refining model for card 12:
```{r}
logit <- glm(label_12 ~ 
               hyperlink_clicked_10 + hyperlink_clicked_11
             + magnify_clicked_9 + magnify_clicked_11
             + expert_clicked_5 + expert_clicked_9
             + time_lt_20_8 + time_lt_20_9 + time_lt_20_10 + time_lt_20_11
             + time_gt_100_8 + time_gt_100_9 + time_gt_100_10 + time_gt_100_11,
             data=train_w, family="binomial")
display_results(logit,train_w,train_w$label_5)
display_results(logit,test_w,test_w$label_5)
```

Regularized regression for card 5:
```{r}
train_w_clean = train_w[complete.cases(train_w),]
yTrain = as.vector(train_w_clean$label_5)
keep = c('hyperlink_clicked_1', 'hyperlink_clicked_2', 'hyperlink_clicked_4', 'hyperlink_clicked_5', 'magnify_clicked_4', 'magnify_clicked_5', 'time_lt_20_1', 'time_lt_20_2', 'time_lt_20_3', 'time_lt_20_4', 'time_lt_20_5', 'time_gt_100_1', 'time_gt_100_2', 'time_gt_100_3', 'time_gt_100_4', 'time_gt_100_5')
xTrain = as.matrix(train_w_clean[keep])
LiblineaR(data=xTrain,target=yTrain,type=6,cost=10,bias=TRUE,verbose=FALSE, cross=10)  #cost=heuristicC(xTrain)
for (i in c(5,10,20,30,50)) {
  m=LiblineaR(data=xTrain,target=yTrain,type=6,cost=i,bias=TRUE,verbose=FALSE, cross=10)
  print(m)
}

m
foo = predict(m,train_w_clean,proba=TRUE)
```

##TODO
Model 12,15,19,21
Re-run models to get AUC for each
Read directions for write-up
Write-up
Write slides (in Beamr?)
Add L1 regularization
Graph results
Model 

#Write-Up
##Background and Intro
This is about MedU dataset

##Initial experiment
1. First I did a broad model to establish taht there was a relationship between student engagement and performance.  In other words, good study habits produce better results.

## Results of initial experiment
Indeed a relationship.  Show how?  With scatter plot?  
1. First say there was significance in model,
1. Say students who did x were y more likely to get answer right

## More detailed experiment
1. Then I broke the data down to identify exactly which components of the lesson cards were useful for achieving better performance
1. Tweaked the models for better accuracy

## Results
List of significant results for each unit. What activities contributed to performance?
May need actual cards to demonstrate this.  
